# Multimodal AI

# Multimodal AI

byLLM supports multimodal inputs including text, images, and videos.

## Installation

-   **Images**: Supported in the default byLLM distribution.
-   **Video**: Requires installing byLLM with the `video` extra:
    ```bash
    pip install byllm[video]
    ```

## Image

Module: `byllm.lib`
Class: `Image`

The `Image` class supports various input forms:

-   **File Paths**: `Image("photo.jpg")`
-   **URLs**: `http://`, `https://`, `gs://` (left as-is)
-   **Data URLs**: `data:image/...;base64,...` (left as-is)
-   **Path-like objects**: `pathlib.Path` (resolved to a local file)
-   **In-memory data**: `bytes`, `bytearray`, `memoryview`, `io.BytesIO` or any file-like object returning bytes.
-   **PIL Image instances**: `PIL.Image.Image`

The `Image` class automatically detects MIME types (including WEBP) and preserves URLs.

### Usage Example

```jac
import from byllm.lib { Model, Image }
import io;
import:py from PIL {Image as PILImage}

glob llm = Model(model_name="gpt-4o");

'Personality of the Person'
enum Personality {
   INTROVERT,
   EXTROVERT
}

sem Personality.INTROVERT = 'Person who is shy and reticent';
sem Personality.EXTROVERT = 'Person who is outgoing and socially confident';

obj Person {
    has full_name: str,
        yod: int,
        personality: Personality;
}

def get_person_info(img: Image) -> Person by llm();

with entry {
    // From file path
    image_from_path = Image("photo.jpg");
    person_obj = get_person_info(image_from_path);
    print(person_obj);

    // From PIL image instance
    pil_img = PILImage.open("photo.jpg");
    img_c = Image(pil_img);

    // From BytesIO buffer
    buf = io.BytesIO();
    pil_img.save(buf, format="PNG");
    img_a = Image(buf);

    // From raw bytes
    raw = buf.getvalue();
    img_b = Image(raw);

    // From data URL
    img_d = Image("data:image/png;base64,<...>");

    // From gs:// link
    img_e = Image("gs://bucket/path/image.png");
}
```

## Video

Module: `byllm.lib`
Class: `Video`

The `Video` class supports video inputs.

### Usage Example

```jac
import from byllm.lib { Model, Video }

glob llm = Model(model_name="gpt-4o");

def explain_the_video(video: Video) -> str by llm();

with entry {
    video_file_path = "SampleVideo_1280x720_2mb.mp4";
    target_fps = 1; // Target frames per second for processing
    video = Video(path=video_file_path, fps=target_fps);
    print(explain_the_video(video));
}
```

## Examples

Multimodal examples demonstrating image and video usage with byLLM are available in the `jac-byllm/examples/vision` repository. These include:

-   `math_solver.jac`
-   `personality_finder.jac`
-   `receipt_analyzer.jac`
-   `mugen.jac`